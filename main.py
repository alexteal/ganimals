# -*- coding: utf-8 -*-
"""Copy of DeiT_Fine_Tuning_on_CIFAR10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IrCKtJPoWM7pGQhEb_QORQRAm51BuiQC

# Hands-on tutorial for DeiT

In this notebook, we show how to use the pre-trained models that we provide with torchhub to perform predictions

## Preliminaries

This section contains the necessary imports, installs and downloads necessary for the remaining of this notebook.
"""

# DeiT is built on top of timm version 0.3.2, so need to install it first
# !pip install timm
# !pip install thop
#
# # Clone DeiT repository
# !git clone https://github.com/facebookresearch/deit.git
#
# # Download ImageNet category names for nicer display
# !wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt

# Commented out IPython magic to ensure Python compatibility.
from PIL import Image
import requests
import matplotlib.pyplot as plt
# %config InlineBackend.figure_format = 'retina'

import torch
import timm
import torchvision
import torchvision.transforms as T
import thop
from thop import profile, clever_format
import torch.utils.data as Data
import torch.nn as nn
from torch.optim.lr_scheduler import CosineAnnealingLR

from deit.models import deit_tiny_patch16_224

from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD

torch.set_grad_enabled(True)

if torch.cuda.is_available():
    device = torch.device('cuda')
    print('CUDA is available. Using GPU.')
else:
    device = torch.device('cpu')
    print('CUDA is not available. Using CPU')

device = torch.device('cpu')
# Read the ImageNet categories
# with open("imagenet_classes.txt", "r") as f:
#     imagenet_categories = [s.strip() for s in f.readlines()]

# create the data transform that DeiT expects
transform = T.Compose([
    T.Resize(256, interpolation=3),
    T.CenterCrop(224),
    T.ToTensor(),
    T.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),
])

"""## Using a pre-trained model from TorchHub

In this section, we show how to load a pre-trained models from torchhub and perform inference with it. In here we will use DeiT-base, but you can use any other model that we provide.

#I ended up not loading it from TorchHub and instead cloned the repository and imported the function from models.py that returns the version of the model I was looking at. This way I can go into the sourc code and modify it/check it as needed so we can fine-tune it
"""

# model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_distilled_patch16_224', pretrained=True)
model = deit_tiny_patch16_224(pretrained=True)
# model.eval()
model = model.to(device)

# for name, weight in model.named_parameters():
# print(name, weight.shape)

"""Let's now retrieve an image from a url and return it as a PIL Image"""

# url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
# im = Image.open(requests.get(url, stream=True).raw)

"""Let's see what the image looks like"""

# im

"""Next, we apply the preprocessing that DeiT expects during inference and run it through the model, computing the 5 classes with highest confidence."""

# transform the original image and add a batch dimension
# img = transform(im).unsqueeze(0)
#
# img = img.to(device)
# model = model.to(device)
#
# # compute the predictions
# out = model(img)
#
# # and convert them into probabilities
# scores = torch.nn.functional.softmax(out, dim=-1)[0]
#
# # finally get the index of the prediction with highest score
# topk_scores, topk_label = torch.topk(scores, k=5, dim=-1)
#
# for i in range(5):
#     pred_name = imagenet_categories[topk_label[i]]
#     print(f"Prediction index {i}: {pred_name:<25}, score: {topk_scores[i].item():.3f}")

"""#Everything below is stuff I added to the original notebook

###Test out a random tensor to get MACs and Params
"""

input_tensor = torch.rand(1, 3, 224, 224).to(device)

macs, params = profile(model, inputs=(input_tensor,))

macs, params = clever_format([macs, params], "%.3f")
print(f"MACs: {macs}, Parameters: {params}")

# Now using CIFAR10 datasets
train_data = torchvision.datasets.CIFAR10(
    root='./data.cifar10/',
    train=True,
    transform=transform,
    download=True
)

test_data = torchvision.datasets.CIFAR10(
    root='./data.cifar10/',
    train=False,
    transform=transform,
    download=True
)

class_dict = {0: "airplane", 1: "automobile", 2: "bird", 3: "cat", 4: "deer", 5: "dog", 6: "frog", 7: "horse",
              8: "ship", 9: "truck"}

batch_size = 1024

train_loader = Data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)
test_loader = Data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)

"""#This just changes the output head to fit the classification size for CIFAR10"""

model.head = nn.Linear(model.embed_dim, 10)

"""#Seeding"""

seed = 1738

torch.manual_seed(seed)
torch.cuda.manual_seed(seed)

torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

"""#Run the CIFAR10 test set through it to see how it does without training on it"""


def test(model=None, test_loader=None, epoch=None, step=None, loss=None):
    # Set the model to evaluation mode
    model.eval()
    model.to(device)

    # Perform evaluation on the dataset
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)  # Send images to the appropriate device (CPU/GPU)
            labels = labels.to(device)

            # Forward pass
            predicted = model(images)  # Assuming model returns (x, x_dist)

            # print(predicted.shape)

            total += labels.size(0)
            correct += (predicted.argmax(dim=1) == labels).sum().item()

    accuracy = correct / total
    print(
        f"Epoch: {epoch + 1}, Step: {step + 1} :: Accuracy on CIFAR-10 test set: {accuracy:.2%}\tRunning Loss for this epoch: {loss:.3}")


"""#Training block"""

for param in model.parameters():
    param.requires_grad = False
last_layer = list(model.children())[-1]
for param in last_layer.parameters():
    param.requires_grad = True

criterion = nn.CrossEntropyLoss()
# optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005 * (batch_size / 512), weight_decay=0.05)
optimizer = torch.optim.SGD(model.parameters(), lr=0.0005 * (batch_size / 512), momentum=0.9, weight_decay=0.005)
scheduler = CosineAnnealingLR(optimizer, T_max=15, eta_min=0)


model.to(device)

num_epochs = 10
for epoch in range(num_epochs):
    print(f"Epoch {epoch}")
    running_loss = 0.0
    for i, data in enumerate(train_loader):
        model.train()
        inputs, labels = data[0].to(device), data[1].to(device)

        train_correct = 0
        train_total = 0

        inputs.requires_grad_()
        optimizer.zero_grad()
        outputs = model(inputs)

        train_total += labels.size(0)
        train_correct = (outputs.argmax(dim=1) == labels).sum().item()
        train_acc = train_correct / train_total

        print(f"Batch accuracy on training data: {train_acc:.2%}")

        loss = criterion(outputs, labels)
        loss.requires_grad_()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        if i % 100 == 99:
            print()
            test(model=model, test_loader=test_loader, epoch=epoch, step=i, loss=running_loss)
            print()
    scheduler.step()
    running_loss = 0.0

print("Training finished")
