# -*- coding: utf-8 -*-
"""Copy of DeiT_Fine_Tuning_on_CIFAR10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IrCKtJPoWM7pGQhEb_QORQRAm51BuiQC

# Hands-on tutorial for DeiT

In this notebook, we show how to use the pre-trained models that we provide with torchhub to perform predictions

## Preliminaries

This section contains the necessary imports, installs and downloads necessary for the remaining of this notebook.
"""

# DeiT is built on top of timm version 0.3.2, so need to install it first
# !pip install timm
# !pip install thop
#
# # Clone DeiT repository
# !git clone https://github.com/facebookresearch/deit.git
#
# # Download ImageNet category names for nicer display
# !wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt

# Commented out IPython magic to ensure Python compatibility.
from PIL import Image
import requests
import matplotlib.pyplot as plt
# %config InlineBackend.figure_format = 'retina'

from SlantedTriangularLR import SlantedTriangularLR
from pruning import run_pruning_tests
import torch
import timm
import os
import matplotlib.pyplot as plt
import torchvision
import torchvision.transforms as T
import thop
from thop import profile, clever_format
import torch.utils.data as Data
import torch.nn as nn
from torch.optim.lr_scheduler import CosineAnnealingLR

from deit.models import deit_tiny_patch16_224

from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD

torch.set_grad_enabled(True)

if torch.cuda.is_available():
    device = torch.device('cuda')
    print('CUDA is available. Using GPU.')
else:
    device = torch.device('cpu')
    print('CUDA is not available. Using CPU')
#print("Using CPU. CUDA might be available.")
#device = torch.device('cpu')
# Read the ImageNet categories
# with open("imagenet_classes.txt", "r") as f:
#     imagenet_categories = [s.strip() for s in f.readlines()]

# create the data transform that DeiT expects
transform = T.Compose([
    T.Resize(256, interpolation=3),
    T.CenterCrop(224),
    T.ToTensor(),
    T.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),
])

"""## Using a pre-trained model from TorchHub

In this section, we show how to load a pre-trained models from torchhub and perform inference with it. In here we will use DeiT-base, but you can use any other model that we provide.

#I ended up not loading it from TorchHub and instead cloned the repository and imported the function from models.py that returns the version of the model I was looking at. This way I can go into the sourc code and modify it/check it as needed so we can fine-tune it
"""

# model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_distilled_patch16_224', pretrained=True)
model = deit_tiny_patch16_224(pretrained=True)
# model.eval()
model = model.to(device)

# for name, weight in model.named_parameters():
# print(name, weight.shape)

"""Let's now retrieve an image from a url and return it as a PIL Image"""

# url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
# im = Image.open(requests.get(url, stream=True).raw)

"""Let's see what the image looks like"""

# im

"""Next, we apply the preprocessing that DeiT expects during inference and run it through the model, computing the 5 classes with highest confidence."""

# transform the original image and add a batch dimension
# img = transform(im).unsqueeze(0)
#
# img = img.to(device)
# model = model.to(device)
#
# # compute the predictions
# out = model(img)
#
# # and convert them into probabilities
# scores = torch.nn.functional.softmax(out, dim=-1)[0]
#
# # finally get the index of the prediction with highest score
# topk_scores, topk_label = torch.topk(scores, k=5, dim=-1)
#
# for i in range(5):
#     pred_name = imagenet_categories[topk_label[i]]
#     print(f"Prediction index {i}: {pred_name:<25}, score: {topk_scores[i].item():.3f}")

"""#Everything below is stuff I added to the original notebook

###Test out a random tensor to get MACs and Params
"""

input_tensor = torch.rand(1, 3, 224, 224).to(device)

macs, params = profile(model, inputs=(input_tensor,))

macs, params = clever_format([macs, params], "%.3f")
print(f"MACs: {macs}, Parameters: {params}")

# Now using CIFAR10 datasets
train_data = torchvision.datasets.CIFAR10(
    root='./data.cifar10/',
    train=True,
    transform=transform,
    download=True
)

test_data = torchvision.datasets.CIFAR10(
    root='./data.cifar10/',
    train=False,
    transform=transform,
    download=True
)

class_dict = {0: "airplane", 1: "automobile", 2: "bird", 3: "cat", 4: "deer", 5: "dog", 6: "frog", 7: "horse",
              8: "ship", 9: "truck"}

batch_size = 1024

train_loader = Data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)
test_loader = Data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)


"""#This just changes the output head to fit the classification size for CIFAR10"""

model.head = nn.Linear(model.embed_dim, 10)

"""#Seeding"""

seed = 2014

torch.manual_seed(seed)
torch.cuda.manual_seed(seed)

torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

"""#Run the CIFAR10 test set through it to see how it does without training on it"""


def test(model=None, test_loader=None, epoch=None, step=None, loss=None):
    # Set the model to evaluation mode
    model.eval()
    model.to(device)

    # Perform evaluation on the dataset
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)  # Send images to the appropriate device (CPU/GPU)
            labels = labels.to(device)

            # Forward pass
            predicted = model(images)  # Assuming model returns (x, x_dist)

            # print(predicted.shape)

            total += labels.size(0)
            correct += (predicted.argmax(dim=1) == labels).sum().item()

    accuracy = 100 * (correct / total)
    print(
        f"Epoch: {epoch + 1}, Step: {step + 1} :: Accuracy on CIFAR-10 test set: {accuracy:.2f}%\tLoss for final batch in this epoch: {loss:.3}")
    return accuracy


def save_model(model, model_name, accuracy):

    highest_accuracy = load_highest_accuracy()

    # Only save the model if its accuracy is higher than the previous model's
    if accuracy > highest_accuracy:

        save_highest_accuracy(accuracy)

        file_path = "./model/{}.pt".format(model_name)

        print("New highest accuracy. Saving model ...")
        print()

        torch.save(model.state_dict(), file_path)
        
        
def load_model(model=None, device="cuda"):
    try:
        model.load_state_dict(torch.load("./model/cifar10_deit_tiny_patch16_224.pt"))
        device = torch.device(device)
        model.to(device)
        model.eval()
        return model
    except Exception as e:
        print(f"Error loading the model: {str(e)}")
        return None
    
    
def load_highest_accuracy():
    if os.path.exists("highest_accuracy.txt"):
        with open("highest_accuracy.txt", "r") as f:
            return float(f.read())
    else:
        return 0.0  # Default to 0.0 if the file doesn't exist
    
    
def save_highest_accuracy(accuracy):
    with open("highest_accuracy.txt", "w") as f:
        f.write(str(accuracy))

        
def plot_accuracy(train_list, test_list):
    epoch_list = [1, 2, 3, 4, 5]
    plt.plot(epoch_list, train_list, label="Training Accuracy", color="blue")
    plt.plot(epoch_list, test_list, label="Testing Accuracy", color="orange")

    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.title("Accuracies At the End of Each Epoch")
    plt.legend()
    plt.savefig('accuracy_plot.png')
    
    
"""#Training block"""
train_list = []
test_list = []
    
# save_dir = "model"
# model_name = "cifar10_deit_tiny_patch16_224"


def train(save_dir="model",
          model_name="cifar10_deit_tiny_patch16_224"): 
    
    if not os.path.exists(save_dir):
            os.makedirs(save_dir)

    for param in model.parameters():
        param.requires_grad = False
    last_layer = list(model.children())[-1]
    for param in last_layer.parameters():
        param.requires_grad = True

        
    num_epochs = 5
    criterion = nn.CrossEntropyLoss()
    # optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005 * (batch_size / 512), weight_decay=0.05)
    optimizer = torch.optim.SGD(model.parameters(), lr=0.0005 * (batch_size / 512), momentum=0.9, weight_decay=0.005)
    scheduler = CosineAnnealingLR(optimizer, T_max=15, eta_min=0)
#     scheduler = SlantedTriangularLR(optimizer, 0.2, 8, 1 * 0.0005 * (batch_size / 512), len(train_loader) * num_epochs)

    model.to(device)

    for epoch in range(num_epochs):
        print(f"Epoch {epoch+1}")
        for i, data in enumerate(train_loader):
            batch_loss = 0.0
            model.train()
            inputs, labels = data[0].to(device), data[1].to(device)

            train_correct = 0
            train_total = 0

            inputs.requires_grad_()
            optimizer.zero_grad()
            outputs = model(inputs)

            train_total += labels.size(0)
            train_correct = (outputs.argmax(dim=1) == labels).sum().item()
            train_acc = train_correct / train_total

            print(f"Batch accuracy on training data: {train_acc:.2%}")

            train_acc = 100 * train_acc
            loss = criterion(outputs, labels)
            loss.requires_grad_()
            loss.backward()
            optimizer.step()
            scheduler.step()

            if i % 5 == 0:
                batch_loss += loss.item()
                print()
                accuracy = test(model=model, test_loader=test_loader, epoch=epoch, step=i, loss=batch_loss)
                print()
                save_model(model, model_name, accuracy)
                
            if i == 48:
                train_list.append(train_acc)
                test_list.append(accuracy)


    print("Training finished")
    
'''
print()
print("Training with STLR")
print()
train()    
plot_accuracy(train_list, test_list)

'''
print()
print("Now testing out pruning")
prune_amounts = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]
run_pruning_tests(model, test_loader, prune_amounts, device)
